---
title: 统计自然语言处理预备知识
date: 2017-11-29 23:30:00
tags: 自然语言处理
categories: NLP
toc: true
---

自然语言处理基础理论

<!--more-->

通常用相对频率作为概率的估计值。这种估计概率值的方法称为最大似然估计（maximum likelihood estimation）。

二项分布：X~B(n,p)

期望值是随机变量所取值的概率平均：
$$E(X)=\sum_{k=1}^\infty x_k p_k$$

方差是随机变量的值偏离其期望值的程度：
$$var(X)=E((X-E(X))^2) = E(X^2) - E^2(X)$$

哈夫曼编码（Huffman Code)是一种编码方式，是可变字长编码方式的一种。

熵又称为自信息，描述一个随机变量的不确定性的数量，表示信源X每发一个符号所提供的平均信息量。
