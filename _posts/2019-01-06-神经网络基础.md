---
title: 神经网络基础
date: 2019-01-06 18:00:00
tags: 神经网络
categories: 深度学习
toc: true
---

基于《深度学习入门》的学习笔记。
<!--more-->

神经网络以损失函数这个指标为线索寻找最优权重参数。

## 损失函数
损失函数是表示神经网络性能的“恶劣程度“的指标，或者反过来说：“使性能的恶劣程度达到最小”等。常用的损失函数：均方误差和交叉熵。

> 特别地，不能以识别精度作为损失函数，原因是：识别精度对于微小的参数变化基本上没有反映，且它的值的变化是不连续地、突然地变化。这也是神经网络的激活函数为什么使用sigmoid函数而不是阶跃函数的原因（阶跃函数的导数在绝大多数地方都为0，而sigmoid函数的斜率不会为0）。

## 梯度
导数的近似计算可以基于“数值微分”的方法（numerical differentiation），比起前向差分和后向差分，更好的方法是使用中心差分（central differences）。
> 说明：关于中心差分优于前向和后向差分的证明可以基于泰勒级数，参考：[俄亥俄大学-数值微分PDF](http://www.ohiouniversityfaculty.com/youngt/IntNumMeth/lecture27.pdf)

有多个变量的函数的导数称为**偏导数**。偏，导数的计算需要将多个变量中的某一个变量定为目标变量，并将其他变量固定为某个值。

梯度的概念：由全部的偏导数汇总而成的向量称为梯度（gradient）。
